
# Packages used
# pip install beautifulsoup4
# pip install lxml
# pip install feedparser
# [OPTIONAL] pip install html5lib


# import urllib2

# target_url = 'https://www.nuget.org/downloads'

# import requests
# from bs4 import BeautifulSoup

# #r = requests.get('https://api.github.com', auth=('user', 'pass'))
# r = requests.get(target_url)

# soup = BeautifulSoup(r.content)

# #print r.status_code
# #print r.headers['content-type']


# from lxml import etree

# target_xpath = '//*[@id="stage-dynamic"]/div[2]/div[1]/div/ul/li[1]/a/span[1]'

# htmlparser = etree.HTMLParser()
# #from StringIO import StringIO
# from io import StringIO
# tree = etree.parse(StringIO(r.text), htmlparser)
# tree.xpath(target_xpath)

import json
try:
    # Python3
    from urllib.request import urlopen
except Exception:
    # Python2
    from urllib import urlopen

from datetime import datetime
from hashlib import md5
from io import StringIO
from lxml import etree

from modules import sw_news_data


################################################################################
# Common functions
################################################################################

def get_content(target_url=None):
    response_content = None
    try:
        http_response = urlopen(target_url)
        response_content = http_response.read()
    except Exception:
        response_content = None
    
    return response_content

def get_json(target_url=None):
    json_data = None
    
    try:
        response_content = get_content(target_url)
        if response_content is None:
            return json_data

        json_data = json.loads(response_content)
    except Exception:
        json_data = None
    
    return json_data

def get_html_tree(target_url=None):
    html_tree = None
    
    try:
        response_content = get_content(target_url)
        if response_content is None:
            return html_tree

        html_parser = etree.HTMLParser()
        html_tree = etree.parse(StringIO(response_content.decode('utf-8')), html_parser)
        
    except Exception:
        html_tree = None
    
    return html_tree


def post_json(target_url, data_dict):
    # data = {"con1":40, "con2":20, "con3":99, "con4":40, "password":"1234"} 
    json_data = json.dumps(data_dict).encode('utf8')
    request_headers = {
        'content-type': 'application/json'
    }
    req = urllib.request.Request(target_url, data=json_data, headers=request_headers)
    response = urlopen(req)
    response_content = response.read()
    return json.loads(response_content)
    #return response_content


################################################################################
# Data scraping (JSON)
################################################################################

def get_md5_hash(strVal):
    return md5(str(strVal).encode('utf-8')).hexdigest()

def get_utc_date():
    return datetime.utcnow().strftime("%Y-%m-%d")


def mk_rec(name, version, last_updated, last_checked, md5_hash):
    return {
        'name': name,
        'version': version,
        'last_updated': last_updated,
        'last_checked': last_checked,
        'md5_hash': md5_hash
    }


########################################
# Data scraping (JSON)
########################################

def scrape_nuget(): 
    target_url = 'https://dist.nuget.org/index.json'
    json_data = get_json(target_url)
    jd = json_data['artifacts'][0]['versions'][0]
    rec = mk_rec(
        'nuget', 
        jd['version'],
        jd['releasedate'],
        get_utc_date(),
        get_md5_hash(jd)
        )
    print(rec)
    sw_news_data.update_software_news(
        current_rec['name'],
        current_rec['version'],
        current_rec['last_updated'],
        current_rec['md5_hash'],
        current_rec['last_checked']
    )
    return rec

########################################
# Data scraping (HTML)
########################################

def scrape_nodejs():
    target_url = 'https://nodejs.org/en/'
    html_tree = get_html_tree(target_url)
    
    # nodejs has 2 versions defined on target_url: LTS and Current

    # LTS case
    target_xpath = '//*[@id="home-intro"]/div[1]/a'
    element_list = html_tree.xpath(target_xpath)
    if len(element_list) > 0:
        e = element_list[0]
        
        rec = mk_rec(
            "nodejs (lts)",
            e.get('data-version'),
            None,
            get_utc_date(),
            get_md5_hash(etree.tostring(e))
        )

        print(rec)
        sw_news_data.update_software_news(
            current_rec['name'],
            current_rec['version'],
            current_rec['last_updated'],
            current_rec['md5_hash'],
            current_rec['last_checked']
        )

    # Current case
    target_xpath = '//*[@id="home-intro"]/div[2]/a'
    element_list = html_tree.xpath(target_xpath)
    if len(element_list) > 0:
        e = element_list[0]
        
        rec = mk_rec(
            "nodejs (current)",
            e.get('data-version'),
            None,
            get_utc_date(),
            get_md5_hash(etree.tostring(e))
        )
        
        print(rec)
        sw_news_data.update_software_news(
            current_rec['name'],
            current_rec['version'],
            current_rec['last_updated'],
            current_rec['md5_hash'],
            current_rec['last_checked']
        )
    


if __name__ == "__main__":
    pass
    from modules import sw_news_data
    sw_news_data.init()

    #scrape_nuget()

    # target_url = 'https://nodejs.org/en/'
    # t = get_content(target_url)
    # htmlparser = etree.HTMLParser()
    # tree = etree.parse(StringIO(t.decode('utf-8')), htmlparser)

    # # LTS
    # target_xpath = '//*[@id="home-intro"]/div[1]/a'
    # # Current
    # elementList = tree.xpath(target_xpath)

    # scrape nodejs
    target_url = 'https://nodejs.org/en/'
    html_tree = get_html_tree(target_url)

    # nodejs has LTS and Current

    # LTS case
    target_xpath = '//*[@id="home-intro"]/div[1]/a'
    element_list = html_tree.xpath(target_xpath)
    if len(element_list) > 0:
        e = element_list[0]
        
        lts_rec = mk_rec(
            "nodejs (lts)",
            e.get('data-version'),
            None,
            get_utc_date(),
            get_md5_hash(etree.tostring(e))
        )
        print(lts_rec)

    # Current case
    target_xpath = '//*[@id="home-intro"]/div[2]/a'
    element_list = html_tree.xpath(target_xpath)
    if len(element_list) > 0:
        e = element_list[0]
        
        current_rec = mk_rec(
            "nodejs (current)",
            e.get('data-version'),
            None,
            get_utc_date(),
            get_md5_hash(etree.tostring(e))
        )
        print(current_rec)


    # HTTP Post
    from urllib.parse import urlencode
    from urllib.request import Request, urlopen

    url = 'http://localhost:50001/api/software/news' # Set destination URL here
    # Set POST fields here
    post_fields = {
        'foo': 'bar'
    }
    r = post_json(url, current_rec)
    
    # newConditions = {"con1":40, "con2":20, "con3":99, "con4":40, "password":"1234"} 
    # params = json.dumps(newConditions).encode('utf8')
    # req = urllib.request.Request(url, data=params, headers={'content-type': 'application/json'})
    # response = urlopen(req)

    # data = {"con1":40, "con2":20, "con3":99, "con4":40, "password":"1234"} 
    # json_data = json.dumps(data).encode('utf8')
    # request_headers = {
    #     'content-type': 'application/json'
    # }
    # req = urllib.request.Request(url, data=json_data, headers=request_headers)
    # response = urlopen(req)
    # r = post_json(url, {"con1":40, "con2":20, "con3":99, "con4":40, "password":"1234"})

    # request = Request(url, urlencode(post_fields).encode())
    # response = urlopen(request)
    ##.read().decode()
    #print(json)
    
    print("[ALL DONE]")
    #print(t)
    
    # {'version': 'v10.15.1', 'last_updated': None, 'name': 'nodejs (lts)', 'last_checked': '2019-02-10', 'md5_hash': 'dfa422fb9a3e39cf4d356b8041431a73'}
    # {
    # 'version': 'v11.9.0', 
    # 'last_updated': None, 
    # 'name': 'nodejs (current)', 
    # 'last_checked': '2019-02-10', 
    # 'md5_hash': 'fe2dc19c2cbd5f7c3d99051ffc413b69'}

    # name, version, last_updated, md5, last_checked
    sw_news_data.update_software_news(
        current_rec['name'],
        current_rec['version'],
        current_rec['last_updated'],
        current_rec['md5_hash'],
        current_rec['last_checked']
    )
    
